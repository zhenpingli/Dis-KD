
## Discriminator enhanced Knowledge Distillation Networks

I have a follow good cloud service code if you want to start the environment directly. I can give you my account number.


Email li_zhenping@126.com

To run the code please follow:
```
python main.py \
    --student_type gpt2 \
    --student_config /home/Gan-Distill/config2.json \
    --teacher_type gpt2 \
    --teacher_name gpt2 \
    --alpha_ce 0  --alpha_cos 0 --alpha_clm 1 \
    --dump_path serialization_dir/my_first_training \
    --data_file data/binarized_text.gpt2.pickle \
    --token_counts data/token_counts.gpt2.pickle \
    --force 
```
The conda env is DisGan.yaml you can use conda to export the env.

The model's trained parameters can be donwnload here:

链接: 

https://pan.baidu.com/s/1eB0qeQYQDWC104SZaoVGaw?pwd=ug3m 

提取码: ug3m 


--来自百度网盘超级会员v6的分享
